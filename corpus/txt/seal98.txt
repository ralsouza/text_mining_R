ACSys
ACSys Data Mining


Data Mining
The Analysis of Large and Complex Datasets

CRC for Advanced Computational Systems
– ANU, CSIRO, (Digital), Fujitsu, Sun, SGI
– Five programs: one is Data Mining
– Aim to work with collaborators to solve real problems and
feed research problems to the scientists
– Brings together expertise in Machine Learning, Statistics,
Numerical Algorithms, Databases, Virtual Environments

Graham Williams



Graham Williams, Senior Research Scientist with CSIRO
Machine Learning
PhD in Ensemble Decision Tree Induction
1

ACSys

ACSys
Outline



The Data Mining Task



Techniques for Data Mining



Case Studies in Data Mining



Research Directions



Wrap Up

So What is Data Mining?



The non-trivial extraction of novel, implicit, and actionable
knowledge from large datasets.
–
–
–
–



2

Extremely large datasets
Discovery of the non-obvious
Useful knowledge that can improve processes
Can not be done manually

Technology to enable data exploration, data analysis, and
data visualisation of very large databases at a high level of
abstraction, without a specific hypothesis in mind.

3

ACSys

ACSys
Knowledge Discovery in Databases

And Where Has it Come From?

Machine
Learning
High
Performance
Computers



Database

–
–
–
–
–
–

Visualisation
Data Mining

Parallel
Algorithms

A six or more step process:

Applied
Statistics

Pattern
Recognition

data warehousing,
data selection,
data preprocessing,
data transformation,
data mining,
interpretation/evaluation



Data Mining is sometimes referred to as KDD



DM and KDD tend to be used as synonyms

4

ACSys

5

ACSys
Techniques Used in Data Mining






Typical Applications of Data Mining



Predictive Modelling
tree induction, neural nets, regression

Sales/Marketing
– Provide better customer service
– Improve cross-selling opportunities (beer and nappies)
– Increase direct mail response rates

Database Segmentation
clustering, k-means, Kohonen maps,



Link Analysis
association rules, sequential patterns, time sequences

Customer Retention
– Identify patterns of defection
– Predict likely defections



Deviation Detection
visualisation, statistics

Risk Assessment and Fraud
– Identify inappropriate or unusual behaviour

7

9

ACSys

ACSys
ACSys Data Mining

Some Research

Mt Stromlo Observatory

NRMA Insurance Limited

Australian Taxation Office
Health Insurance Commission



Interestingness through Evolutionary Computation



Virtual Environments



Data Mining Standards



Temporal Data Mining



Spatial Data Mining



Feature Selection

10

ACSys

11

ACSys
Outline



Outline



The Data Mining Task



Techniques for Data Mining



Case Studies in Data Mining



Research Directions



Wrap Up

The Data Mining Task
–
–
–
–
–

12

History
Motivation
Disciplines
Definitions
The Process

13

ACSys

ACSys
Why Data Mining Now?



The Growth in KDD



Changes in the Business Environment
– Customers becoming more demanding
– Markets are saturated



–
–
–
–

Drivers



– Focus on the customer, competition, and data assets



Research Community
KDD Workshops 1989, 1991, 1993, 1994
KDD Conference annually since 1995
KDD Journal since 1997
ACM SIGKDD http://www.acm.org/sigkdd

Commercially
– Research: IBM, Amex, NAB, AT&T, HIC, NRMA
– Services: ACSys, IBM, MIP, NCR, Magnify
– Tools: TMC, IBM, ISL, SGI, SAS, Magnify

Enablers
– Increased data hoarding
– Cheaper and faster hardware
14

ACSys

15

ACSys
Outline



The Scientist’s Motivation


The Data Mining Task
–
–
–
–
–

The Real World
– Offers many challenging problems
– Enormous databases now exist and readily available

History
Motivation
Disciplines
Definitions
The Process



Statistics building models and doing analysis for years?
– Statistics limited computationally
– Relevance of statistics if we do not sample
– There are not enough statisticians to go around!



Machine Learning to build models?
– Limited computationally, useful on toy problems, but . . .

16

17

ACSys

ACSys
Motivation: The Sizes



Outline



Databases today are huge:
– More than 1,000,000 entities
– From 10 to 10,000 entities
– Giga-bytes and tera-bytes



Databases a growing at an unprecendented rate



The corporate world is a cut-throat world

The Data Mining Task
–
–
–
–
–

History
Motivation
Disciplines
Definitions
The Process

– Decisions must be made rapidly
– Decisions must be made with maximum knowledge

18

ACSys

21

ACSys
Databases

Multiple Disciplines

Machine
Learning
High
Performance
Computers



Database



Visualisation
Data Mining

Parallel
Algorithms

OLTP

)

=

OLAP

)

=

OLAM

Data Warehouses
– Subject-oriented, integrated, time-variant, non-volatile
– Once created then what?
– Excellent starting point for Data Mining

Applied
Statistics

Pattern
Recognition

22



Data Marts: Specialised, smaller, data store



OLAP: Drill-down, roll-up, slice-n-dice, data cubes

23

ACSys

ACSys
From OLAP to Data Mining



On-Line Analytical Processing
–
–
–
–



Statistics

Emphasis on Query
Generally know what we want to find
Expressible in SQL
Drill-Down, Data Cubes

Data, Counting, Probabilities, Hypothesis testing



Prediction
– Friedman: CART, MARS, PRIM

Data Mining
–
–
–
–



Emphasis on Exploration
Generally idea of the target but not how to find
Let the machine drive the exploration
OLAM: Drill-Down, Data Cubes



All important, but no longer by themselves



Sampling is the antithesis of Data Mining

24

ACSys

25

ACSys
Machine Learning

Visualisation



Decision Trees and Classification Rules



Exploratory data analysis has long history



Neural Networks



Visualisation in Data Mining



K Nearest Neighbours and Clustering



Genetic Algorithms



Association Rules



All useful, but computationaly thirsty

– Understanding the data
– Visualising the process
– Visualising the results of mining

26

27

ACSys

ACSys
High Performance Computing

Software Engineering



Very large datasets—need rapid access to data



SE Practices apply to DM practises



Very slow algorithms—need to improve



Developing architectures for Data Mining

– Address computational complexity
– Parallel algorithms



Developing APIs for data and models

28

ACSys

29

ACSys
Discovering Knowledge

Outline





The Data Mining Task
–
–
–
–
–

The non-trivial extraction of novel, implicit, and actionable
knowledge from large datasets.
– Novel = not previously known
– Implicit = not easily identifiable
– Actionable = can act upon the discoveries

History
Motivation
Disciplines
Definitions
The Process




30

Knowledge equates to patterns or models
Generally we are searching for symbolic descriptions of
novel and interesting patterns that are contained in the data.
These patterns generally apply to a particular area of the
database.
31

ACSys

ACSys
The Key is the Hypothesis




Data Mining in a Nutshell



Data mining “discovers information without a previously
formulated hypothesis:” We don’t particularly know what we
are looking for. We hope to find un-thought of discoveries.



Compare with:
–
–
–
–
–
–



SQL Queries
Information Retrieval
OLAP
Exploratory Data Analysis
Visualisation
Statistics

Start with a raw database
) RDBMS or Warehouse
Collect and aggregate variables in a variety of ways
) dataset D
Then mine the data: search for patterns implicit in the data
and determining whether they are interesting

32

ACSys

33

ACSys
Formally



Dataset

Generating Candidate Nuggets

D of real world entities D = fe1; e2; : : : ; eng.



 D is relational: R(A1; A2; : : : ; Am)


Each entity is a tuple hv1; v2; : : : ; vmi



The number of attributes m and the number of tuples n are
typically “large” (m may be anywhere from 20 to 1000 and n
typically greater than 1,000,000)




Generate a set of nuggets

If inducing rules which symbolically describe the nuggets
then we equivalently have R = fr1; r2; : : : ; rpg
Rule might consist of conjunction of conditions:
–
–

34

N = fn1; n2; : : : ; npg

Ai 2 [v1; v2] for numeric attributes
Ai 2 fv1; v2; : : : ; vq g for categorical attributes.

35

ACSys

ACSys
Assessing Interestingness



Nuggets N



Generally p
exploration.



However, p can still be large (several thousand)



How do we measure the interestingness of a nugget?



Different approaches employ different measures



This question we come back to later

=

Outline

f n 1 ; n2 ; : : : ; n p g



 n so becoming more amenable to human

The Data Mining Task
–
–
–
–
–

History
Motivation
Disciplines
Definitions
The Process

36

ACSys

37

ACSys
Data Mining is a Process



The CRISP-DM



A standard six step process is being developed:
–
–
–
–
–
–



Business Understanding (25%)
Data Understanding (20%)
Data Preparaation (25%)
Modelling (10%)
Evaluation (20%)
Deployment



Being championed by NCR, Daimler-Benz, ISL, OHRA
Cross Industry Standard Process for Data Mining
http://www.ncr.dk/CRISP/index.htm
Define and validate a Data Mining Process Model
– applicable in diverse industry sectors
– industry and tool neutral
– large data mining projects executed faster, cheaper, more
reliably and more manageably


38

Life cycle of six (iterative) phases.
39

ACSys

ACSys
Business Understanding





Data Understanding

Initial phase focuses on understanding project objectives
and requirements from a business perspective
This knowledge is converted into a data mining problem
definition



Initial data collection



Familiarisation with the data
– identify data quality problems
– discover first insights into the data
– detect interesting subsets to form hypotheses for hidden
information

Develop a preliminary plan designed to achieve the
objectives

41

ACSys

42

ACSys
Data Preparation



Construct the mining dataset



Derived from the initial raw dataset(s)



Data preparation tasks:
–
–
–
–

Preparing to Mine



Data Quality
– missing data
– noisy data
– lead to inconsistent or too general/specific discoveries



table, record, and attribute selection
generation of derived features
data transformation
data cleaning

Data Cleaning
– duplicates
– inconsistencies
– identify and merge the same entities

43

44

ACSys

ACSys
Modelling—The Actual Data Mining



Select various modelling techniques



Apply and calibrate modelling techniques




Evaluation




Typically there are several techniques for the same data
mining problem



Some techniques have specific requirements on the form
of data and require stepping back to the data preparation
phase



Evaluate the model and review the steps executed to
construct the model
Does the model properly achieve the business objectives?
Is there some important business issue that has not been
sufficiently considered?
Decide on the use of the data mining results

45

ACSys

46

ACSys
Deployment





The KDD Process



An interative process, often requiring multiple loops

– Generate a report of the discoveries made
– Implement changes in the processes of the organisation
– Implement a repeatable data mining process



Time consuming process



The actual mining is one small step in the whole process

For successful deployment the customer must understand
the actions to be carried out in order to actually make use of
the created models



Issues in data management are crucial to success

Deployment may be:

47

48

ACSys

ACSys
Outline



Data Mining Operations



The Data Mining Task



Techniques for Data Mining



Case Studies in Data Mining



Research Directions



Wrap Up





Predictive Modelling (supervised learning)
use observations to learn to predict
Database Segmentation (unsupervised learning)
partition data into similar groups
Link Analysis
links between individuals rather than characterising whole
Deviation Detection
outlier detection: becoming a major focus of data mining

49

ACSys

50

ACSys
Predictive Modelling: Classification



Classification: C5.0



Goal of classification is to build structures from examples
of past decisions that can be used to make decisions for
unseen cases.



Quinlan: ID3

)

=

C4.5

)

=

C5.0

Most widely used Machine Learning and Data Mining tool
Started as Decision Tree Induction, now Rule Induction, also



Often referred to as supervised learning.



Decision Tree and Rule induction are popular techniques



Available from http://www.rulequest.com/



Neural Networks also used



Many publically available alternatives


51

CART developed by Breiman et al. (Stanford)
Salford Systems http://www.salford-systems.com
52

ACSys

ACSys
Decision Tree Induction




Algorithm

Decision tree induction is an example of a recursive
partitioning algorithm
Basic motivation:
–
–
–
–

A dataset contains a certain amount of information
A random dataset has high entropy
Work towards reducing the amount of entropy in the data
Alternatively, increase the amount of information exhibited
by the data

53

ACSys

54

ACSys
Algorithm

Discriminating Descriptions



Construct set of candidate partitions S



Typical algorithm considers a single attribute at one time:



Select best S* in S



categorical attributes



Describe each cell Ci in S*



Test termination condition on each Ci

– define a disjoint cell for each possible value: sex = “male”
– can be grouped: transport 2 (car, bike)



– true: form a leaf node
– false: recurse with Ci as new training set

continuous attributes
– define many possible binary partitions
– Split A < 24 and A  24
– Or split A < 28 and A  28

55

56

ACSys

ACSys
Information Measure



 info(T )

A decision tree produces a message which is the decision



The information content is

Pmj

=1

,pj log(pj )

– pj is the probability of making a particular decision
– there are m possible decisions
Same as entropy:

Pmj

=1

Pm

=
j =1 ,pj log(pj ) is the amount of information
needed to identify class of an object in T

Estimate the gain in information from a particular partitioning
of the dataset





Information Measure



Maximised when all pj are equal



Minimised (0) when all but one pj is 0 (the remaining pj is 1)



Now partition the data into n cells



pj log(1=pj ).

P

Expected information requirement is then the weighted sum:
infox(T ) = ni=1 jjTTijj  info(Ti)

57

ACSys

58

ACSys
End Result

Information Measure



The information that is gained by partitioning T is then:

b

gain(A) = info(T ) , infox(T )




A

c

E
This gain criterion can then be used to select the partition
which maximises information gain

Y

<63

>=63

Y

N

Variations of the Information Gain have been developed to
avoid various biases: Gini Index of Diversity

59

60

ACSys

ACSys
Pruning





Error-Based Pruning

We may be able to build a decision tree which perfectly
reflects the data
But the tree may not be generally applicable
called overfitting



Replace sub-trees with leaves



Decision class is the majority



Pruning based on predicted error rates
– prune subtrees which result in lower predicted error rate

Pruning is a technique for simplifying and hence
generalising a decision tree

61

ACSys

62

ACSys
Issues

Pruning



How to estimate error? Use a separate test set:
– Error rate on training set (resubstitution error) not useful
because pruning will always increase error
– Two common techniques are cost-complexity pruning and
reduced-error pruning






Unknown attribute values



Run out of attributes to split on



Cost Complexity Pruning: Predicted error rate modelled as
weighted sum of complexity and error on training set—the
test cases used to determine weighting




Reduced Error Pruning: Use test set to assess error rate
directly
63

Brittleness of method—small perturbations of data lead to
significant changes in decision trees
Trees become too large and are no longer particularly
understandable (thousands of nodes)
Data Mining: Accuracy, alone, is not so important

64

ACSys

ACSys
Classification Rules



Pros and Cons of Decision Tree Induction



A tree can be converted to a rule set by traversing each path

b

A

E

Y
>=63

Y

N

– A=c)Y
– A = b ^ E < 63 ) Y
– A = b ^ E  63 ) N
– Rule Pruning: Perhaps E

–
–
–
–

c

<63

Pros



Greedy Search = Fast Execution
High dimensionality not a problem
Selects important variables
Creates symbolic descriptions

Cons
– Search space is huge
– Interaction terms not considered
– Parallel axis tests only (A = v )

 63 ) N
65

ACSys

66

ACSys
Recent Research



Predictive Modelling: Regression



Bagging

– Limited use and biased by outliers

– Sample with resubstitution from training set
– Build multiple decision trees from different samples
– Use a voting method to classify new objects



Linear Regression



Non-Linear Regression
– Difficult with high dimensional data

Boosting



– Build multiple trees from all training data
– Maintain a weight for each instance in the training set that
reflects its importance
– Use a voting method to classify new objects

Radial Basis Functions
– More robust and flexible
– Weighted sum of non-linear functions, each fitted to
separate regions
– Selection of regions is now important

67

68

ACSys

ACSys
Predictive Modelling: Neural Networks

Input Nodes

Data Input

Hidden Nodes

Nearest Neighbour Approaches



Output
Nodes

Data Flow

Data Out

Compare a new entity with all other entities to find the
nearest-neighbours



Assign the new entity the most popular decision!



A lazy learner (no generalisation until necessary)

Inactive Nodes

Active Nodes

69

ACSys

70

ACSys
Link Analysis: Association Rules

Database Segmentation: Clustering






Definition:
– Given n entities find a useful partition into p subsets

– Given
 A dataset of customer transactions
 A transaction is a collection of items
– Find
 Correlations between items as rules

Numerical Clustering
– Usually easier since distance easy to calculate
– For example, Euclidean distance



A technique developed specifically for data mining



Conceptual Clustering

Examples
– Supermarket baskets
– Attached mailing in direct marketing

– Targets the derivation of the cluster
– Symbolic descriptions
– Can handle non-numeric data
71

72

ACSys

ACSys
Example

Determining Interesting Association Rules



Rules have confidence and support

Transaction
12345
12346
12347
12348

– IF x and y THEN z with confidence c
 if x and y are in the basket, then so is z in c% of cases
– IF x and y THEN z with support s
 the rule holds in s% of all transactions

Items
ABC
AC
AD
BEF



Input Parameters: confidence = 50%; support = 50%



if A then C: c = 66.6% s = 50%



if C then A: c = 100% s = 50%

73

ACSys

74

ACSys
Typical Application



Hundreds of thousands of different items



Millions of transactions



Many gigabytes of data



It is a large task, but linear algorithms exist

Itemsets are Basis of Algorithm
Transaction
12345
12346
12347
12348

75

Items
ABC
AC
AD
BEF



Rule A ) C



s = s(A; C ) = 50%



c = s(A; C )/s(A) = 66.6%

Itemset

A
B
C
A; C

Support
75%
50%
50%
50%

76

ACSys

ACSys
Algorithm Outline



HIC Example



Find all large itemsets
– sets of items with at least minimum support
– Apriori and AprioriTid and newer algorithms



– 6.8 million records X 120 attributes (3.5GB)
– 15 months preprocessing then 2 weeks data mining



Generate rules from large itemsets
– For ABCD and AB in large itemset the rule AB
holds if ratio s(ABCD)/s(AB) is large enough
– This ratio is the confidence of the rule

Associations on episode database for pathology services

) CD

Goal: find associations between tests
– cmin = 50% and smin = 1%, 0.5%, 0.25%
(1% of 6.8 million = 68,000)
– Unexpected/unnecessary combination of services
– Refuse cover saves $550,000 per year

77

ACSys

78

ACSys
Outline



The Data Mining Task



Techniques for Data Mining



The Hot Spots Methodology



– How to partition the data?
Finding the nuggets
– How to assess interestingness?
Weighing the nugget

Case Studies in Data Mining



Research Directions



Wrap Up

Search for interesting areas within a very large database



79

In our case studies we have found clustering and rule
induction to work together well to identify nuggets
We are still novices in properly weighing the nuggets

81

ACSys

ACSys
Mining the Knowledge Mine







ACSys Data Mining

Data-driven approach to generate the rules
– Cluster D into a set of subsets
– Describe each subset using Classification
– To generate nuggets R = fr1; r2; : : : ; rpg.

Mt Stromlo Observatory

While p is generally much smaller than n (p  n) it can
still be substantial (perhaps one or two thousand for n in
the millions). p generally remains too large for manual
consideration.

NRMA Insurance Limited

Australian Taxation Office

Manual and time-consuming process of analysing lots of
statistics about the groups that “looked” interesting.

Health Insurance Commission
82

ACSys

83

ACSys
Macho

Micro-Lensing

MAssive Compact Halo Objects
The search for the dark matter of the Universe
20 million stars recorded nightly for over 4 years
Search for micro lensing events

84

85

ACSys

ACSys
Sample Star Light Curves

Transformed into Feature Space

0.0

Time Series mapped into Feature Space
Fourier Transforms, Auto-Regression, Wavelets, . . .

-0.2

-0.1

Intensity

0.1


450

500

550

600

Intensity

-0.3

-0.1

0.1

0.2

Time (days)

450

500

550

600

550

600

550

600

Cluster stars using feature space



Investigate outliers

0.0
-0.1
-0.2

Intensity

0.1

Time (days)



450

500

0.05
0.0
-0.05

Intensity

0.10

Time (days)

450

500
Time (days)

86

ACSys

87

ACSys
NRMA: Motor Vehicle Insurance

0.4

Approach: Cluster then Describe then Measure

0.2

0.3

Insurance premium setting and risk rating

0.1

Star 1135
•

•

•
Star 1058
•
Star 1023

•
•
•
•
•
• •
••
• Star 1125
•
• •
•
•• ••••••••••• • •• •
• Star 1118
•••••
•
••••••••••••
•
• •• •••••••••••••••
•
• •
•
• Star 1121 •
• • ••••• • •• •
• Star 1124
•
•
Star 1113 •
Star 1112 •
•

-0.2

-0.1

0.0

Star 1045

-0.2

-0.1

0.0

0.1

0.2

0.3

0.4

88



Actuaries study data and domain to define general formula



Several million transactions annually



Better understand dynamics of the areas of risk



Consider more than the traditional small number of factors
89

ACSys

ACSys
Cluster then Describe then Measure

. .... . .. .
.... . .
.
...
. .. ..
. . .. . .
.

Find the Interesting Groups
Rule 1
Rule 23

ClmCost694
(319,1681)

... . .
.. ..
.....
..
..
.
....... .
.

H
 HHHH

HH
HH

HHH

HH


SumRqst15500
(107,218)

SnyType8
(212,1463)

H
 HHHH

H
ClmCost21

`1'–0.269912
(61,165)

(46,53)
HH
 HHH

H
VehModel145

`1'–0
(0,6)

HH
 HH
Postcode2142
(46,47)

(28,15)
HHH

Cost = $95,000

`1'–0.388889 `0'–0.16
(7,11)
(21,4)

HH
 HHHH

H
ClmCost3850

H
 HHHH

H

`1'–0.109637
(157,1275)

(55,188)

`1'–0.0526316
(4,72)

`1'–0.36
(18,32)

Cost = $ 158,000

Exp13

(51,116)
HHHH
 Cubic
H2.4

H
 HH

`1'–0.113636
(10,78)

(41,38)

`1'–0.314286 `0'–0.318182
(11,24)
(30,14)

< 60 and Age  24 and Address is Urban
> 57 and Vehicle 2 fUtility, Station Wagong

NCB
Age

Nugget

Claims

Total

Proportion

1
2
3
4
5
6
7
...
60

150
140
5
10
20
65
5

1400
2300
25
120
340
520
5

11
6
20
8
6
13
100

Average Cost
3700
3800
4400
7900
5300
4400
6800

Total Cost
545,000
535,000
13,000
79,100
116,000
280,700
20,300

800

1400

5.9

3500

2,800,000

All

3800

72000

5.0

3000

12,000,000

90

ACSys

91

ACSys
Finding the Interesting Groups

Find the Interesting Groups
Rule 1
Rule 23

Evaluate the large collection of groups (or Hot Spots) to find
those that are important to the core business.
Nugget
2
3
19
24
34
35
36
40

By Claims

By Proportion

By Average Cost

Y
Y
Y
Y
Y
Y

Y
Y

Y
Y
Y
Y

92

< 60 and Age  24 and Address is Urban
> 57 and Vehicle 2 fUtility, Station Wagong

NCB
Age

Nugget

Claims

Total

Proportion

Average Cost

Total Cost

1
2
3
4
5
6
7
...
60

150
140
5
10
20
65
5

1400
2300
25
120
340
520
5

11
6
20
8
6
13
100

3700
3800
4400
7900
5300
4400
6800

800

1400

5.9

3500

2,800,000

All

3800

72000

5.0

3000

12,000,000

545,000
535,000
13,000
79,100
116,000
280,700
20,300

93

ACSys

ACSys
Health Insurance Commission

Cluster then Describe then Measure

Medicare




. .... . .. .
.... . .
.
...
. .. ..
. . .. . .
.

Terabytes of patient claims since the inception of Medicare
Inappropriate Provider practices an ongoing focus



Exploration of public fraud (including doctor shoppers)



Exploration of the practise of pathology

ClmCost694
(319,1681)

... . .
.. ..
.....
..
..
.
....... .
.



H
 HHHH








HH
HH

SumRqst15500
(107,218)






`1'–0
(0,6)

HHHH

`1'–0.109637
(157,1275)

HH

VehModel145
(46,47)

HH
 HH
Postcode2142
HHH
(28,15)

Cost = $95,000

HH

HH
 HHHH

H
ClmCost3850

ClmCost21
(46,53)

`1'–0.269912
(61,165)

HHH

SnyType8
(212,1463)

HHHH
HH

H
 HHHH
(55,188)



`1'–0.0526316
(4,72)

`1'–0.36
(18,32)

Cost = $ 158,000

H

Exp13
(51,116)

HHHH
 Cubic
H2.4

H
 HH

`1'–0.113636
(10,78)

`1'–0.388889 `0'–0.16
(7,11)
(21,4)

(41,38)

`1'–0.314286 `0'–0.318182
(11,24)
(30,14)

94

ACSys

95

ACSys
Cluster then Describe then Deliver
Rule 1
Rule 2

HIC Time Plots

Age is between 18 and 25 and Weeks  10
Weeks 10 and Benefits $350

<

>

Accumulated Daily Processing 70102 (4)

Accumulated Daily Processing 70191 (13)

180000

25000

160000

ugget

Size

Age

Gender

Services

Benefits

Weeks

Hoard

Regular

1
2
3
4
5
6
...
280

9000
150
1200
80
90
800

30
30
65
45
10
55

F
F
M
F
M
M

10
24
7
30
12
8

30
841
220
750
1125
550

2
4
20
10
10
7

1
2
1
1
5
1

1
4
1
1
2
9

30

25

F

15

450

15

2

6

All

40,000

45

8

30

3

1

1

20000

140000

120000
15000

96

100000

80000
10000
60000

40000

5000

20000

0
12700

12800

12900

13000

13100

13200

13300

0
12700

12800

12900

13000

13100

13200

13300

But there may be several thousand of these.

97

ACSys

ACSys
Medicare Regulars

Claim Hoarders

Group of patients with very regular activity:

A distinct group of behaviour identified as Claim Hoarders

pina17307520484

pin17307520484

300
pin17300440631

pin17305130174

700

45
Service-Claim

pin17305600270

35

Service-Claim

30

Service-Claim

Service-Claim

Service-Claim

40
250

600

30

500

25

400

20

35

25
200

30

20
25
150
20

15

300

15
100

15

10

200

10

10
50

100

5

5

5

0
12600
12700

12800

12900

13000

13100

13200

13300

13400

0
12600

12700

12800

12900

13000

13100

13200

13300

13400

0
12600

12700

12800

12900

13000

13100

13200

13300

12700

12800

12900

13000

13100

13200

13300

13400

0
12600

12700

12800

12900

13000

13100

13200

13300

13400

13400

Remove non-cash payments!!!
But there may be many millions of these.

98

ACSys

99

ACSys
Australian Tax Office





Fraud Prevention and Control

Identifying a tax avoidance scheme

Discover nuances that can establish tax payer has nonlegitimate (possibly fraudulent) claims

TxblInc
SlryWgs
TxInst
WrkDed



ATO

Hot Spot
1
2
3
4
5
6
7
8
9
10
11
12

Conventional statistical techniques not working: more than
looking for averages, outliers, etc.
Effective selection of possible hits (not too many)

100

Size
238
1221
25 534
55
19
1184
198 234
4356
1417
14
8
473

...

SpseRbt

0
12600

101

ACSys

ACSys
Interestingness

Outline



The Data Mining Task



We are drowning in a wealth of “discoveries”



Techniques for Data Mining



Visualisation is not enough—VR beginning to help.



Case Studies in Data Mining








Research Directions
Wrap Up



Still need a better way to help us interactively explore
through the space of possible groupings of the data.
Combined with VR to provide a data driven yet user
controlled exploratory data mining system
We need a way of better exploring the space and identifying
interestingness more formally.

102

ACSys

103

ACSys
Fitness = Interestingness





Rule Induction



We cast our problem to that of searching for a collection of
data subsets (described by rules) which we find interesting
Our rule set R can serve as a starting point for the
search (although randomly generated starting points could
be used).



Rule Evolution is not new, but
We do not seek rule accuracy in the usual sense
We do not seek coverage in the usual sense

Instead we seek a collection of rules that describe different
regions of the database and are interesting.

If we can define what we mean by interesting then we could
use that as out fitness measure to evolve a fitter collection
of rules.

104

105

ACSys

ACSys
Specifying Interestingness



Specifying interestingness is now the difficult task.



There are many aspects to take into account.




How to Capture Interestingness



We can capture interestingness as some formula involving:
– Distance
A measure of how far a group prototype is from the
population prototype.
– Template
A pattern that is used to increase the interestingness
measure.
– Belief
Well know truths of the domain to check for surprising
discoveries.
– Sizes
Size of corresponding dataset and complexity of rule

The domain user will essentially refine their idea of
interestingness as they proceed in their exploration
Keep the domain user in the look: In an evolutionary
sense, maintain them as the oracle to decide fitness of the
interestingness measure

106

ACSys

107

ACSys

An Architecture for Evolutionary Hot Spots

Other Research Directions

h a formal language for expressing interestingness we can now explore the evolution of
fitness measure itself, allowing the data driven discoveries to be assessed by the domain
r, whose input is captured to evolve measures of interestingness which are then employed
evolve new nuggets!
Dataset

Ruleset

Hot Spots
Sample







Virtual Environments
Data Mining Standards
Temporal Data Mining
Spatial Data Mining
Feature Selection

Human
Ranking

Evolve

s=3

(q*s)

p = 1000
Evolve

Analysis

Measures of
Interestingness
q=5
n = 1,000,000
m = Attributes

108

109

ACSys

ACSys
Virtual Environments






Standardisation Issues
 Standard Architectures
 Standard Interfaces

The screen is too limited in what it can present visually
Virtual environments provide considerably more real-estate
Explore the results of data mining

– Data Access Interfaces
– Model Communication Interfaces

Rely on the significant human ability for perception
– Pick up patterns in the forrest of trees that catch the eye

110

ACSys

111

ACSys
Temporal Data Mining

Standard Architecture





Plug-Ins
Visualise
VR Cave

Workbench

XML

XML

GUI
Execute

XML

Data
Extraction
Agent

Schema

Statistical
Summary
Visualise

Associatns

Fast
Summaries

XML

Segments

Rules
JDBC/ODBC/OLE

Time is an issue in many databases
Most OLTP systems are time-based transactional systems
Yet, we tend to factor time out to do Data Mining
How can we use time directly in Data Mining?
– Temporal Logics
– Temporal Databases

Data Access API

Read Many
Data Cubes
Write Rarely
Fast Data Cube Generation

RDBMS

112

113

ACSys

ACSys
Spatial Data Mining






Feature Selection
 Once we have the right features data mining is trivial!
 But how do we best aggregate the source features?

Spatial Inforation Systems (and GIS) now common technology
Spatial Databases store Spatially Indexed data
Again, in Data Mining we tend to factor space out!
How can we use spatial information directly in Data Mining?

– Aggregate transactions in some way:
number of transactions every 3 months
number of different types of transactions
– Aggregate spatial data appropriately:
in particular census collection disctrict
 But the aggregations encapsulate preconceived ideas

114

ACSys

115

ACSys
Outline







Outline

The Data Mining Task

 Wrap Up

Techniques for Data Mining
Case Studies in Data Mining
Research Directions

– Tools
– Privacy

Wrap Up

116

117

ACSys

ACSys
IBM: Intelligent Miner

The Data Mining Vendor Space

 A collection of tools to handle organisational/transactional data for Data

 Visit http://www.cmis.CSIRO.AU/Graham.Williams/dataminer/Catalogue.html
 Over 60 vendors in the market today

Mining.

 Some of the best Data Mining research from IBM research labs, but not

– A crowded market
– Tool Vendors versus Service Providers
– Sales of less than 30!
 Market Share: IBM, ISL, SAS, SGI, TMC

all of it captured in Intelligent Miner

 Techniques: Association, Segmentation, Time Sequence, NN, Rules
 Client/Server with Java-based GUI—reasonably intuitive

118

ACSys

119

ACSys
ISL: Clementine

SAS: Enterprise Miner

 Was first with an excellent point-n-click interface for Data Mining
 Took the drudgery out of linking lots of tools together
 Under the bonnet, standard collection of techniques, including C5.0, NN,

 Integration with the SAS world is a big benefit
 Standard techniques: Clustering, Decision Trees, Linear and Logistic
Regression, Neural Networks
 Still in beta and seeking stability

clustering, associations, etc.

 Newest release addressing standardisation issues

120

121

ACSys

ACSys
SGI: MineSet






TMC: Darwin
 The “first” data mining tool to market?
 Early Versions

Hot on visualisations
Excellent for exploring the data to understand it
Contains usual collection of basic tools

– Connection Machine
– Provided NN and Decision Trees
 Current Versions
– Client (NT) / Server (Unix)
– Ease-of-use
– More model builders

Allows other tools to plug-in (e.g., AutoClass from UltiMode)

122

ACSys

123

ACSys
Privacy and Data Mining

OECD Principles of Data Collection

 Laws in many countries directly affect Data Mining, and it is worth being

 Collection limitation:

aware of them—penalties are often severe.
 The OECD Principles of Data Collection are relevant.

Data should be obtained lawfully and fairly, while some very sensitive
data should not be held at all
 Data quality:
Data should be relevant to the stated purposes, accurate, complete and
up-to-date; proper precautions should be taken to ensure this accuracy
 Purpose specification:
The purposes for which data will be used should be identified, and the
data should be destroyed if it no longer serves the given purpose

124

125

ACSys

ACSys
OECD Principles of Data Collection

OECD Principles of Data Collection

 Use limitation:

 Individual participation:

Use of data for purposes other than specified is forbidden, except with
the consent of the data subject or by authority of law
 Security safeguards:
Agencies should establish procedures to guard against loss, corruption,
destruction, or misuse of data
 Openness:
It must be possible to acquire information about the collection, storage,
and use of personal data

The data subject has a right to access and challenge the data related to
him or her
 Accountability:
A data controller should be accountable for complying with measures
giving effect to all these principles

126

ACSys
Further Information
 http://www.cmis.csiro.au/Graham.Williams/DataMiner
 Discovering Data Mining by Cabena, Hadjinian, Stadler, Verhees, and
Zanasi. Prentice Hall, 1998.
 Data Warehousing, Data Mining, and OLAP by Berson and Smith.
McGraw-Hill, 1997
 Machine Learning by Mitchell. McGraw-Hill, 1997

128

127

